{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e888c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting FAST conversion...\n",
      "ðŸ“Š train: 10969 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10969/10969 [14:35<00:00, 12.53img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train: 10969 new, 0 skipped\n",
      "ðŸ“Š val: 2735 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2735/2735 [05:03<00:00,  9.02img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… val: 2735 new, 0 skipped\n",
      "ðŸ“Š test: 2698 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2698/2698 [04:53<00:00,  9.19img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… test: 2698 new, 0 skipped\n",
      "\n",
      "ðŸŽ‰ DONE in 1474.2s!\n",
      "ðŸ“Š 16402 images processed\n",
      "ðŸ“ Created: CAFD_YOLO/\n",
      "ðŸ“„ YAML: cafd_yolo.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def create_yolo_dataset_fast():\n",
    "    \n",
    "    print(\"ðŸš€ Starting FAST conversion...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Paths\n",
    "    source_base = Path('./CAFD')\n",
    "    target_base = Path('./CAFD_YOLO')\n",
    "    \n",
    "    # Create directories\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (target_base / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (target_base / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Class names\n",
    "    class_names = [\n",
    "        \"achichuk\", \"airan-katyk\", \"asip\", \"bauyrsak\", \"beshbarmak-w-kazy\",\n",
    "        \"beshbarmak-wo-kazy\", \"chak-chak\", \"cheburek\", \"doner-lavash\", \"doner-nan\",\n",
    "        \"hvorost\", \"irimshik\", \"kattama-nan\", \"kazy-karta\", \"kurt\", \"kuyrdak\",\n",
    "        \"kymyz-kymyran\", \"lagman-fried\", \"lagman-w-soup\", \"lagman-wo-soup\", \"manty\",\n",
    "        \"naryn\", \"nauryz-kozhe\", \"orama\", \"plov\", \"samsa\", \"shashlyk-chicken\",\n",
    "        \"shashlyk-chicken-v\", \"shashlyk-kuskovoi\", \"shashlyk-kuskovoi-v\",\n",
    "        \"shashlyk-minced-meat\", \"sheep-head\", \"shelpek\", \"shorpa\", \"soup-plain\",\n",
    "        \"sushki\", \"suzbe\", \"taba-nan\", \"talkan-zhent\", \"tushpara-fried\",\n",
    "        \"tushpara-w-soup\", \"tushpara-wo-soup\"\n",
    "    ]\n",
    "    \n",
    "    class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    def process_split_fast(source_path, target_images, target_labels, split_name):\n",
    "        if not source_path.exists():\n",
    "            print(f\"âš ï¸  {split_name} not found\")\n",
    "            return 0, 0\n",
    "        \n",
    "        total_files = sum(len(list((source_path / class_name).glob('*.jpg'))) \n",
    "                         for class_name in class_names \n",
    "                         if (source_path / class_name).exists())\n",
    "        \n",
    "        if total_files == 0:\n",
    "            return 0, 0\n",
    "        \n",
    "        print(f\"ðŸ“Š {split_name}: {total_files} images\")\n",
    "        \n",
    "        image_count = 0\n",
    "        skipped = 0\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(total=total_files, desc=f\"Processing {split_name}\", unit=\"img\")\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            class_path = source_path / class_name\n",
    "            if not class_path.exists():\n",
    "                continue\n",
    "                \n",
    "            class_id = class_to_id[class_name]\n",
    "            \n",
    "            for img_file in class_path.glob('*.jpg'):\n",
    "                target_img = target_images / img_file.name\n",
    "                target_txt = target_labels / f\"{img_file.stem}.txt\"\n",
    "                \n",
    "                # Skip if already exists\n",
    "                if target_img.exists() and target_txt.exists():\n",
    "                    skipped += 1\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Copy image\n",
    "                shutil.copy2(img_file, target_img)\n",
    "                \n",
    "                # Create annotation\n",
    "                with open(target_txt, 'w') as f:\n",
    "                    f.write(f\"{class_id} 0.5 0.5 1.0 1.0\\n\")\n",
    "                \n",
    "                image_count += 1\n",
    "                pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "        print(f\"âœ… {split_name}: {image_count} new, {skipped} skipped\")\n",
    "        return image_count, image_count\n",
    "    \n",
    "    # Process splits\n",
    "    train_imgs, _ = process_split_fast(\n",
    "        source_base / 'train', \n",
    "        target_base / 'train' / 'images',\n",
    "        target_base / 'train' / 'labels',\n",
    "        \"train\"\n",
    "    )\n",
    "    \n",
    "    val_imgs, _ = process_split_fast(\n",
    "        source_base / 'val',\n",
    "        target_base / 'val' / 'images', \n",
    "        target_base / 'val' / 'labels',\n",
    "        \"val\"\n",
    "    )\n",
    "    \n",
    "    test_imgs, _ = process_split_fast(\n",
    "        source_base / 'test',\n",
    "        target_base / 'test' / 'images',\n",
    "        target_base / 'test' / 'labels', \n",
    "        \"test\"\n",
    "    )\n",
    "    \n",
    "    # Create YAML\n",
    "    yaml_content = f\"\"\"\n",
    "    train: {target_base.absolute()}/train\n",
    "    val: {target_base.absolute()}/val\n",
    "    test: {target_base.absolute()}/test\n",
    "    nc: {len(class_names)}\n",
    "    names: {class_names}\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('./cafd_yolo.yaml', 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    total_imgs = train_imgs + val_imgs + test_imgs\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ DONE in {duration:.1f}s!\")\n",
    "    print(f\"ðŸ“Š {total_imgs} images processed\")\n",
    "    print(f\"ðŸ“ Created: CAFD_YOLO/\")\n",
    "    print(f\"ðŸ“„ YAML: cafd_yolo.yaml\")\n",
    "    \n",
    "    return target_base\n",
    "\n",
    "# Run fast conversion\n",
    "yolo_dataset = create_yolo_dataset_fast()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
